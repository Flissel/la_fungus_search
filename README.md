# EmbeddingGemma Desktop Setup ðŸ”

Ein vollstÃ¤ndiges Desktop-Interface fÃ¼r Google's EmbeddingGemma-300M Modell mit GUI, CLI und RAG-System.

## Abstract

EmbeddingGemma kombiniert lokale Embeddings mit einem Physarum-inspirierten Multiâ€‘Agentenâ€‘Retriever (MCMP) und optionaler Enterpriseâ€‘RAGâ€‘Suche:
- **Embeddings + UI**: Klassische semantische Suche (Streamlit `app.py`) und MCMPâ€‘RAG OberflÃ¤che (`mcmp_streamlit.py`, `streamlit_fungus.py`).
- **MCMPâ€‘RAG**: Viele Agenten bewegen sich im Embeddingâ€‘Raum, hinterlassen Pheromonspuren, dÃ¤mpfen Trails und aktualisieren fortlaufend Dokumentâ€‘Relevanzen; am Ende werden Topâ€‘K Chunks mit optionaler DiversitÃ¤t zurÃ¼ckgegeben.
- **Codeâ€‘Space Frontend**: `streamlit_fungus.py` durchsucht Pythonâ€‘Repos Ã¼ber mehrstufige Chunks (Header: `# file: â€¦ | lines: a-b | window: w`), unterstÃ¼tzt Multiâ€‘Query, Autoâ€‘Generierung (LLM, grounded auf eingebetteten Dateien) und **Dedup** der Queries.
- **Agentâ€‘Chat & Tools**: Chatâ€‘Agent mit Toolâ€‘Calls (z. B. Codeâ€‘Suche, Rootâ€‘Dir setzen), Hintergrundâ€‘Reports mit Liveâ€‘Progress und optionaler Snapshotâ€‘GIFâ€‘Aufzeichnung.
- **Enterpriseâ€‘RAG**: Qdrant + LlamaIndex fÃ¼r persistente Indizes (Ragâ€‘Modus im Fungusâ€‘UI), Hybridâ€‘Scoring und Antwortâ€‘Generierung.
- **API & Coding Events**: `src/embeddinggemma/fungus_api.py` inkl. Endpoint zum Bauen von Codeâ€‘Editâ€‘Events aus Chunkâ€‘Headern; optionales Publizieren in eine Queue.

## ðŸš€ Schnellstart

### 1. Setup ausfÃ¼hren
```bash
# Doppelklick auf setup.bat oder im Terminal:
setup.bat
```

### 2. Hugging Face Setup
- Bei [Hugging Face](https://huggingface.co) registrieren
- [EmbeddingGemma Lizenz](https://huggingface.co/google/embeddinggemma-300m) akzeptieren
- Falls nÃ¶tig: HF Token erstellen und setzen

### 3. Anwendung starten

#### ðŸŒ Web-Interface (Empfohlen)
```bash
streamlit run app.py
```
Dann Browser Ã¶ffnen: http://localhost:8501

#### ðŸ” Kommandozeile
```bash
# Einfache Suche
python cli.py search "Wie funktioniert KI?" --docs "Machine Learning Tutorial" "Python Guide" "AI Basics"

# Similarity Matrix
python cli.py similarity "Text 1" "Text 2" "Text 3"

# Aus Datei suchen
python cli.py file-search "Deine Frage" documents.txt
```

#### ðŸ“š RAG System
```bash
# Demo starten
python rag.py demo

# Interaktive Suche
python rag.py interactive

# Dokumente hinzufÃ¼gen und speichern
python rag.py add --file documents.txt --save meine_wissensbasis
```

## ðŸ”§ Features

### Web-Interface (app.py)
- **Text Suche**: Query vs. Dokumente Similarity
- **Batch Analyse**: CSV-Dateien verarbeiten
- **Similarity Matrix**: Interaktive Heatmaps
- **Export Funktionen**: Cache-Management
- **Responsives Design**: Plotly Visualisierungen

### CLI Tool (cli.py)
- **Flexible Suche**: Ein-Zeilen-Kommandos
- **File-Support**: Textdateien durchsuchbar
- **JSON Export**: Strukturierte Ausgabe
- **Batch Processing**: Mehrere Texte gleichzeitig

### RAG System (rag.py)
- **Wissensbasis**: Dokumente persistent speichern
- **FAISS Integration**: Schnelle Vektorsuche
- **Interactive Mode**: Terminal-Chat
- **Metadata Support**: Erweiterte Dokumentinfos

## ðŸ“ Struktur

```
EmbeddingGemma/
â”œâ”€â”€ app.py              # Streamlit Web-Interface
â”œâ”€â”€ cli.py              # Kommandozeilen-Tool
â”œâ”€â”€ rag.py              # RAG System
â”œâ”€â”€ requirements.txt    # Python Dependencies
â”œâ”€â”€ setup.bat          # Windows Setup-Script
â”œâ”€â”€ embedding_cache/   # Model Cache
â”œâ”€â”€ rag_cache/         # RAG Wissensbasis Cache
â””â”€â”€ README.md          # Diese Datei
```

## ðŸŽ¯ AnwendungsfÃ¤lle

### ðŸ“š Dokumentensuche
Durchsuche groÃŸe Textsammlungen semantisch:
```bash
python rag.py add --file meine_dokumente.txt --save firmen_kb
python rag.py search "Wie implementiere ich Feature X?" --load firmen_kb
```

### ðŸ” Content Discovery
Finde Ã¤hnliche Inhalte in deiner Sammlung:
```bash
python cli.py similarity "Artikel 1" "Artikel 2" "Artikel 3" --output similarity.json
```

### ðŸ¤– AI-Pipeline Integration
Nutze als Embedding-Service fÃ¼r grÃ¶ÃŸere Systeme:
```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("google/embeddinggemma-300m")
embeddings = model.encode(["Dein Text"])
```

## âš™ï¸ Konfiguration

### Embedding-Dimensionen
- **768**: Beste QualitÃ¤t (Standard)
- **512**: Guter Kompromiss
- **256**: Schnell, weniger Speicher
- **128**: Sehr schnell, Mobile-optimiert

### Performance-Tipps
- **GPU**: Automatische CUDA-Nutzung falls verfÃ¼gbar
- **Batch-Size**: Bei groÃŸen Datenmengen anpassen
- **Cache**: Wird automatisch verwendet
- **Dimensionen**: FÃ¼r Speed/Storage-Tradeoff reduzieren

## ðŸ› Troubleshooting

### Model Download Fehler
```bash
# HF Token setzen (falls nÃ¶tig)
huggingface-cli login
```

### CUDA Fehler
```bash
# CPU-only Installation
pip install torch --index-url https://download.pytorch.org/whl/cpu
```

### Import Fehler
```bash
# Dependencies neu installieren
pip install -r requirements.txt --force-reinstall
```

## ðŸ”— Links

- [EmbeddingGemma Model](https://huggingface.co/google/embeddinggemma-300m)
- [Google AI Blog](https://developers.googleblog.com/en/introducing-embeddinggemma/)
- [Sentence Transformers](https://www.sbert.net/)
- [FAISS Documentation](https://faiss.ai/)

## ðŸ“Š Model Info

- **Parameter**: 308M (100M Model + 200M Embedding)
- **Sprachen**: 100+ Sprachen
- **Context**: 2048 Token
- **Performance**: MTEB #1 unter 500M Parametern
- **Lizenz**: Gemma (kommerziell nutzbar)

## ðŸƒâ€â™‚ï¸ Quick Examples

### Web-Interface verwenden
1. `streamlit run app.py`
2. Text in "Suchanfrage" eingeben
3. Dokumente in "Dokumente" Bereich (eine Zeile = ein Dokument)
4. "Suche starten" klicken

### CLI fÃ¼r schnelle Tests
```bash
# Schnelle Similarity-PrÃ¼fung
python cli.py search "Python Tutorial" --docs "Learn Python Programming" "JavaScript Guide" "Java Basics"

# Output als JSON
python cli.py search "AI Tutorial" --docs "ML Guide" "DL Basics" --output results.json
```

### RAG fÃ¼r Projekte
```bash
# Wissensbasis aufbauen
echo "Python ist eine Programmiersprache" > docs.txt
echo "Machine Learning nutzt Algorithmen" >> docs.txt
python rag.py add --file docs.txt --save projekt_kb

# Suchen
python rag.py search "Was ist Python?" --load projekt_kb
```

Viel SpaÃŸ beim Experimentieren mit EmbeddingGemma! ðŸš€


## ðŸ§  MCMP-RAG: Schleimpilz-inspirierte Suche

**Neu!** Monte Carlo Physarum Machine (MCPM) fÃ¼r revolutionÃ¤re Dokumentenexploration, inspiriert vom Foraging-Verhalten des Schleimpilz *Physarum polycephalum*.

### ðŸŒŸ Was macht MCMP-RAG besonders?

**Statt statischer Vektorsuche:**
- **Adaptive Agenten** erkunden den Dokumentenraum dynamisch
- **Pheromonspur-basierte Pfadfindung** zwischen verwandten Dokumenten
- **Emergente Netzwerk-Strukturen** decken versteckte Verbindungen auf
- **Multi-hop Reasoning** Ã¼ber mehrere Dokumente hinweg

### ðŸš€ MCMP-RAG verwenden

#### ðŸŒ Web-Interface
```bash
# MCMP-RAG mit Streamlit starten
streamlit run mcmp_streamlit.py

# Oder Ã¼ber Batch-Script
start_mcmp.bat
```

#### ðŸ–¥ï¸ Kommandozeile
```bash
# Schnelle Suche
python mcmp_cli.py search "Wie funktioniert KI?" --docs "AI Tutorial" "ML Guide" "DL Basics"

# Interaktiver Modus
python mcmp_cli.py interactive

# Benchmark verschiedener Konfigurationen
python mcmp_cli.py benchmark --file documents.txt --queries "Query 1" "Query 2"

# Demo ausfÃ¼hren
python mcmp_cli.py demo
```

#### ðŸ§ª Python API
```python
from mcmp_rag import MCPMRetriever

# MCMP System initialisieren
mcmp = MCPMRetriever(num_agents=500, max_iterations=100)

# Dokumente hinzufÃ¼gen
documents = ["Doc 1", "Doc 2", "Doc 3"]
mcmp.add_documents(documents)

# Suche mit Schleimpilz-Algorithmus
results = mcmp.search("Meine Frage", top_k=5)

# Ergebnisse analysieren
for result in results['results']:
    print(f"[{result['relevance_score']:.3f}] {result['content']}")

# Netzwerk visualisieren
mcmp.visualize_search_process("search_analysis.png")
```

### ðŸ”§ MCMP Parameter

| Parameter | Standard | Beschreibung |
|-----------|----------|-------------|
| `num_agents` | 300 | Anzahl MCPM-Agenten |
| `max_iterations` | 80 | Maximale Suchiterationen |
| `pheromone_decay` | 0.95 | Pheromonspur-Abklingrate |
| `exploration_bonus` | 0.1 | Exploration vs. Exploitation |

### ðŸ“Š MCMP vs. Standard RAG

| Feature | Standard RAG | MCMP-RAG |
|---------|-------------|----------|
| **Suchstrategie** | Statische Vektorsuche | Adaptive Agenten-Exploration |
| **Dokumentverbindungen** | Keine | Emergente Netzwerke |
| **Pfadfindung** | Single-hop | Multi-hop Reasoning |
| **LernfÃ¤higkeit** | Statisch | Dynamische Anpassung |
| **Ãœberraschungsfaktor** | Gering | Hoch (Serendipity) |

### ðŸŽ¯ AnwendungsfÃ¤lle

#### ðŸ“š **Akademische Forschung**
- Literaturrecherche mit versteckten Verbindungen
- Cross-Domain Wissenstransfer
- InterdisziplinÃ¤re Konzeptentdeckung

#### ðŸ¢ **Unternehmens-Wissensbasen**
- Komplexe Policy-Suche
- Innovative LÃ¶sungsansÃ¤tze
- Team-Ã¼bergreifende Expertise-Findung

#### ðŸ” **Content Discovery**
- Unerwartete thematische Verbindungen
- Content-Gap-Analyse
- Trend-Vorhersage durch Netzwerk-Analyse

### ðŸ“ˆ Performance-Tipps

```python
# FÃ¼r groÃŸe Dokumentensammlungen (>1000 Docs)
mcmp = MCPMRetriever(
    num_agents=1000,       # Mehr Agenten fÃ¼r bessere Abdeckung
    max_iterations=150,    # LÃ¤ngere Exploration
    exploration_bonus=0.2  # Mehr ZufÃ¤lligkeit
)

# FÃ¼r schnelle Prototyping
mcmp = MCPMRetriever(
    num_agents=100,        # Weniger Agenten
    max_iterations=50,     # KÃ¼rzere Suche
    exploration_bonus=0.05 # Fokussierte Suche
)
```

### ðŸ§¬ Algorithmus-Details

MCPM basiert auf dem Foraging-Verhalten von *Physarum polycephalum*:

1. **Agent Spawning**: Agenten starten um Query-Embedding
2. **Attraction Forces**: Bewegung zu relevanten Dokumenten
3. **Pheromone Deposition**: Erfolgreiche Pfade werden markiert
4. **Trail Following**: Andere Agenten folgen starken Spuren
5. **Network Emergence**: Stabile Verbindungsstrukturen entstehen
6. **Relevance Extraction**: Finale Dokumenten-Rankings

### ðŸ“– Inspiration & Referenzen

- **Polyphorm Paper**: [Polyphorm: Structural Analysis of Cosmological Datasets](https://arxiv.org/abs/2009.02441)
- **Original Repository**: [CreativeCodingLab/Polyphorm](https://github.com/CreativeCodingLab/Polyphorm)
- **Physarum-Algorithmen**: Jones, Jeff (2010). "Characteristics of pattern formation and evolution in approximations of Physarum transport networks"

---

## âœ… TODO: Coding Events & Queue Integration

Diese Sektion markiert anstehende Arbeiten rund um Code-Edit-Events, damit der Hauptâ€‘Agent (Producer) eine Redisâ€‘Queue speisen kann und ein Coderâ€‘Agent (Consumer) gezielte Edits ausfÃ¼hrt.

- [ ] API vervollstÃ¤ndigen: Codeâ€‘Editâ€‘Event bauen und optional verÃ¶ffentlichen
  - Endpoint (bereits vorhanden): `POST /api/edit/build_event` in `src/embeddinggemma/fungus_api.py`
  - Zweck: Aus einem RAGâ€‘Chunkâ€‘Header `# file: <pfad> | lines: a-b | window: w` exakte Dateipfade und Zeilengrenzen extrahieren, optional via AST auf eine Methode einschrÃ¤nken, und ein neutrales Editâ€‘Event erzeugen.
- [ ] Redisâ€‘Integration finalisieren
  - Env: `REDIS_URL`, `CODER_EVENTS_KEY` (Standard: `coder:events`)
  - Zweck: Bei `publish=true` das Event als JSON in die Queue pushen, damit der Coderâ€‘Agent es konsumieren kann.
- [ ] Eventâ€‘Schema konsolidieren (Platzhalter â€“ Werte spÃ¤ter befÃ¼llen)
  ```json
  {
    "id": "<uuid>",
    "type": "code_edit_request",
    "file_path": "<pfad.py>",
    "start_line": <int>,
    "end_line": <int>,
    "instructions": "<was zu Ã¤ndern ist>",
    "before": "<optional: aktueller Code>",
    "bounds_source": "<chunk_header|explicit>",
    "chunk_header": "# file: <pfad> | lines: <a>-<b> | window: <w>",
    "prefer_method": "<optional: funktionsname>",
    "meta": { "query": "<ursprungsfrage>", "score": <float>, "source": "<rag|mcmp|manual>" },
    "routing": { "return_queue": "coder:results", "notify_webhook": "<optional_url>" },
    "control": { "priority": "<low|normal|high>", "timeout_s": <int>, "dry_run": <true|false> },
    "correlation_id": "<trace/run id>"
  }
  ```
- [ ] Clientâ€‘Snippet (Beispiel):
  ```bash
  curl -X POST http://localhost:8055/api/edit/build_event \
    -H "Content-Type: application/json" \
    -d '{
      "chunk_text": "# file: src\\embeddinggemma\\rag.py | lines: 1-277 | window: 800\n...",
      "prefer_method": "search",
      "instructions": "Refaktor: Benenne Variable x in query_text um.",
      "publish": true,
      "extra": {"issue_id": 123}
    }'
  ```

Hinweis: Separatorâ€‘Linien (`-----`) kÃ¶nnen in Datendateien fÃ¼r Lesbarkeit genutzt werden. FÃ¼r das eigentliche Embedding oder die Editâ€‘Grenzen werden die Headerâ€‘Metadaten bevorzugt, weil sie exakte Dateiâ€‘ und Zeilenbereiche liefern.

