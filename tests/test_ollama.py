#!/usr/bin/env python3
"""
Schneller Test fÃ¼r Ollama Integration
"""

import requests
import json

def test_ollama_connection():
    """Teste Ollama Verbindung"""
    print("ğŸ”Œ Teste Ollama Verbindung...")
    
    try:
        # Liste verfÃ¼gbare Modelle
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            models = response.json()["models"]
            print(f"âœ… Ollama lÃ¤uft! VerfÃ¼gbare Modelle:")
            for model in models:
                print(f"  - {model['name']} ({model['size'] // 1024**3:.1f}GB)")
            return models[0]["name"] if models else None
        else:
            print(f"âŒ Ollama nicht erreichbar: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"âŒ Verbindungsfehler: {e}")
        return None

def test_chat(model_name):
    """Teste Chat mit Modell"""
    print(f"\nğŸ’¬ Teste Chat mit {model_name}...")
    
    try:
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": model_name,
                "prompt": "Hallo! Antworte auf Deutsch mit maximal 20 WÃ¶rtern.",
                "stream": False
            },
            timeout=30
        )
        
        if response.status_code == 200:
            answer = response.json()["response"]
            print(f"ğŸ¤– Antwort: {answer}")
            return True
        else:
            print(f"âŒ Chat Fehler: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Chat Fehler: {e}")
        return False

def main():
    print("ğŸš€ Ollama Integration Test")
    print("=" * 40)
    
    # Teste Verbindung
    model_name = test_ollama_connection()
    
    if model_name:
        # Teste Chat
        success = test_chat(model_name)
        
        if success:
            print("\nâœ… Ollama Integration erfolgreich!")
            print("\nğŸ¯ NÃ¤chste Schritte:")
            print("1. streamlit run ollama_rag.py")
            print("2. Oder: python ollama_rag.py 'Deine Frage hier' --docs example_documents.txt")
        else:
            print("\nâŒ Chat-Test fehlgeschlagen")
    else:
        print("\nâŒ Ollama nicht verfÃ¼gbar")
        print("\nğŸ’¡ LÃ¶sungen:")
        print("1. Ollama starten: 'ollama serve'")
        print("2. Modell pullen: 'ollama pull llama3.2:1b'")

if __name__ == "__main__":
    main()
