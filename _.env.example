# Backend LLM
OLLAMA_MODEL=qwen2.5-coder:7b
OLLAMA_HOST=http://127.0.0.1:11434
OLLAMA_SYSTEM=You are a precise code analysis assistant. Output strict JSON as requested.
OLLAMA_NUM_GPU=1
OLLAMA_NUM_THREAD=12
OLLAMA_NUM_BATCH=128

# Embeddings
# If EMBEDDING_MODEL is unset and OPENAI_API_KEY is present, the backend defaults to openai:text-embedding-3-large.
# Otherwise it falls back to google/embeddinggemma-300m.
EMBEDDING_MODEL=openai:text-embedding-3-large
DEVICE_MODE=auto

# Backend port
EMBEDDINGGEMMA_BACKEND_PORT=8011



# Choose your provider
LLM_PROVIDER=openai

# OpenAI
OPENAI_MODEL=gpt-4o
OPENAI_API_KEY=sk-...           # paste your key
OPENAI_BASE_URL=https://api.openai.com
OPENAI_TEMPERATURE=0.0

# Vector backend (Qdrant)
VECTOR_BACKEND=qdrant
QDRANT_URL=http://localhost:6339
QDRANT_COLLECTION=codebase
# QDRANT_API_KEY=

# Run artifacts (optional)
# RUN_ID=run_123

# Alternatively Google
# LLM_PROVIDER=google
# GOOGLE_MODEL=gemini-1.5-pro
# GOOGLE_API_KEY=...
# GOOGLE_BASE_URL=https://generativelanguage.googleapis.com
# GOOGLE_TEMPERATURE=0.0

# Or Grok
# LLM_PROVIDER=grok
# GROK_MODEL=grok-2-latest
# GROK_API_KEY=...
# GROK_BASE_URL=https://api.x.ai
# GROK_TEMPERATURE=0.0